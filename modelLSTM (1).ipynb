{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--aF7Ye0AGGC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NVj8MAgB_wvj",
        "outputId": "ed3b7dfc-4007-4fa4-b41e-7dd87f620866"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('filtered_input_matrix.csv')\n",
        "\n",
        "# Prepare the features and labels\n",
        "X_flat = data.iloc[:, :-1].values  # excluding the last column\n",
        "y = data.iloc[:, -1].values  # the last column is the target\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_flat_resampled, y_resampled = smote.fit_resample(X_flat, y_encoded)\n",
        "\n",
        "# Reshape X to (num_samples, 9, 3) AFTER applying SMOTE\n",
        "X_resampled = X_flat_resampled.reshape(-1, 9, 3)\n",
        "y_categorical = to_categorical(y_resampled)\n",
        "\n",
        "# Now, you split your data into training, validation, and testing sets.\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_categorical, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(9, 3)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dropout(0.2),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluation on test data\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "metrics = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Printing evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {metrics[0]}\")\n",
        "print(f\"Recall: {metrics[1]}\")\n",
        "print(f\"F1 Score: {metrics[2]}\")\n",
        "\n",
        "# Plotting training and validation loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9VYEKO9kHRPS",
        "outputId": "ca7b82e9-8f66-40f9-e2d7-48aafe4857b9"
      },
      "outputs": [],
      "source": [
        "# NO SMOTE\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('filtered_input_matrix.csv')\n",
        "\n",
        "# Prepare the features and labels\n",
        "X = data.iloc[:, :-2].values.reshape(-1, 9, 3)  # Reshape X to (num_samples, 9, 3)\n",
        "y = data.iloc[:, -2].values  # the last column is the target\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Split your data into training, validation, and testing sets.\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y_categorical, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(9, 3)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dropout(0.2),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluation on test data\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "metrics = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Printing evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {metrics[0]}\")\n",
        "print(f\"Recall: {metrics[1]}\")\n",
        "print(f\"F1 Score: {metrics[2]}\")\n",
        "\n",
        "# Plotting training and validation loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs. Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfS518k764nh",
        "outputId": "a50cb6f6-e46a-4c11-c6a5-39c25a362486"
      },
      "outputs": [],
      "source": [
        "y_dum = [5]*len(y_true)\n",
        "y_dum2 = np.random.randint(0, 6, size=len(y_true))\n",
        "\n",
        "model_accuracy = accuracy_score(y_true, y_pred)\n",
        "base_accuracy = accuracy_score(y_true,y_dum)\n",
        "base_random_accuracy = accuracy_score(y_true,y_dum2)\n",
        "\n",
        "# print(\"Our model accuracy:\",  model_accuracy)\n",
        "print(\"Duplicates base model accuracy:\", base_accuracy)\n",
        "print(\"Random base model accuracy:\", base_random_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
